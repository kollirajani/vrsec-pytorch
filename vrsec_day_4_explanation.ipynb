{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM50tMb7M4boyWpS5ub2Toe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kollirajani/vrsec-pytorch/blob/main/vrsec_day_4_explanation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u0FE1EjSPv1l"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "E10cONe1P1Em"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "This code is about training a neural network to recognize different types of flowers based on measurements like petal length, petal width, etc. Let's break it down step by step in simple terms.\n",
        "\n",
        "1. What Are We Doing?\n",
        "We are training a computer program (a neural network) to recognize three different types of Iris flowers:\n",
        "\n",
        "Setosa\n",
        "Versicolor\n",
        "Virginica\n",
        "We will feed the program flower measurements (like petal length and width), and it will learn to predict which type of flower it is.\n",
        "\n",
        "2. Understanding the Neural Network\n",
        "A neural network is a series of connected layers that help process information and make predictions.\n",
        "This network has:\n",
        "\n",
        "Input Layer: Takes in the flower measurements (4 numbers).\n",
        "Hidden Layers: Two layers (8 and 9 neurons) that help the network learn patterns.\n",
        "Output Layer: Gives a prediction (one of the 3 flower types).\n",
        "ðŸ‘‰ Think of this like a decision-making system.\n",
        "Just like your brain recognizes a dog vs. a cat based on features (ears, tail, fur), this model will recognize flowers using petal and sepal sizes.\n",
        "\n",
        "3. Breaking Down the Code\n",
        "Step 1: Import Libraries\n",
        "python\n",
        "Copy\n",
        "Edit\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "torch: A tool for building and training neural networks.\n",
        "pandas: Helps us work with tables of data.\n",
        "matplotlib.pyplot: Helps us make graphs.\n",
        "sklearn: Helps split the data into training and testing sets.\n",
        "Step 2: Building the Model\n",
        "python\n",
        "Copy\n",
        "Edit\n",
        "class Model(nn.Module):\n",
        "    def __init__(self, in_features=4, h1=8, h2=9, out_features=3):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(in_features, h1)\n",
        "        self.fc2 = nn.Linear(h1, h2)\n",
        "        self.out = nn.Linear(h2, out_features)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.out(x)\n",
        "        return x\n",
        "This defines a neural network.\n",
        "The input is 4 features (petal/sepal size).\n",
        "It has two hidden layers to process the information.\n",
        "It uses ReLU activation (a function that helps decide which neurons to activate).\n",
        "The output is 3 values, each representing a flower type.\n",
        "Step 3: Load the Flower Data\n",
        "python\n",
        "Copy\n",
        "Edit\n",
        "url = 'https://gist.githubusercontent.com/curran/.../iris.csv'\n",
        "my_df = pd.read_csv(url)\n",
        "Downloads a dataset containing flower measurements.\n",
        "Converts the names (setosa, versicolor, virginica) into numbers (0, 1, 2).\n",
        "Step 4: Preparing the Data\n",
        "python\n",
        "Copy\n",
        "Edit\n",
        "x = my_df.drop('species', axis=1).values\n",
        "y = my_df['species'].values\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=41)\n",
        "Splits the data into two groups:\n",
        "Training data (80%) â€“ used to teach the model.\n",
        "Testing data (20%) â€“ used to check if the model learned correctly.\n",
        "Step 5: Convert Data for Training\n",
        "python\n",
        "Copy\n",
        "Edit\n",
        "x_train = torch.FloatTensor(x_train)\n",
        "x_test = torch.FloatTensor(x_test)\n",
        "y_train = torch.LongTensor(y_train)\n",
        "y_test = torch.LongTensor(y_test)\n",
        "Converts the data into a format that PyTorch can understand.\n",
        "Step 6: Set Up Training\n",
        "python\n",
        "Copy\n",
        "Edit\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "Loss function (criterion): Measures how far off the predictions are.\n",
        "Optimizer (Adam): Adjusts the weights to make better predictions.\n",
        "Learning rate (lr=0.01): Controls how fast the model learns.\n",
        "Step 7: Train the Model\n",
        "python\n",
        "Copy\n",
        "Edit\n",
        "epochs = 1000\n",
        "losses = []\n",
        "for i in range(epochs):\n",
        "  y_pred = model.forward(x_train)\n",
        "  loss = criterion(y_pred, y_train)\n",
        "  losses.append(loss.detach().numpy())\n",
        "\n",
        "  if i % 10 == 0:\n",
        "    print(f'Epoch: {i} and loss: {loss}')\n",
        "\n",
        "  optimizer.zero_grad()\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "Runs the training 1,000 times (epochs = 1000).\n",
        "Each time:\n",
        "Makes a prediction (y_pred).\n",
        "Calculates error (loss).\n",
        "Updates the model to improve accuracy.\n",
        "Plots a graph to show how the error decreases.\n",
        "Step 8: Test the Model\n",
        "python\n",
        "Copy\n",
        "Edit\n",
        "with torch.no_grad():\n",
        "    y_eval = model.forward(x_test)\n",
        "    loss = criterion(y_eval, y_test)\n",
        "Turns off training mode (we donâ€™t need to update weights).\n",
        "Makes predictions on new test data.\n",
        "Checks how accurate the model is.\n",
        "Step 9: Evaluate Accuracy\n",
        "python\n",
        "Copy\n",
        "Edit\n",
        "correct = 0\n",
        "with torch.no_grad():\n",
        "    for i, data in enumerate(x_test):\n",
        "        y_val = model(data)\n",
        "        if y_val.argmax().item() == y_test[i]:\n",
        "            correct += 1\n",
        "print(f\"We got {correct} correct!\")\n",
        "Counts how many predictions were correct.\n",
        "Prints how well the model did.\n",
        "Conclusion\n",
        "This neural network learned to classify flowers based on their measurements.\n",
        "If trained correctly, it can look at new flower data and predict the right type with high accuracy! ðŸš€\n",
        "\n",
        "Let me know if you need a simpler explanation or an analogy"
      ],
      "metadata": {
        "id": "hdPxWP7DQ4s4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "In this program, we used several important PyTorch modules to build, train, and evaluate the neural network. Here are the key ones:\n",
        "\n",
        "1. torch.nn (Neural Network Module)\n",
        "This module provides the building blocks for neural networks.\n",
        "\n",
        "Used components:\n",
        "\n",
        "nn.Module â†’ Base class for all neural networks.\n",
        "nn.Linear â†’ Creates fully connected (dense) layers.\n",
        "nn.CrossEntropyLoss â†’ Loss function for multi-class classification.\n",
        "Example from the code:\n",
        "\n",
        "python\n",
        "Copy\n",
        "Edit\n",
        "class Model(nn.Module):\n",
        "    def __init__(self, in_features=4, h1=8, h2=9, out_features=3):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(in_features, h1)  # First layer\n",
        "        self.fc2 = nn.Linear(h1, h2)  # Second layer\n",
        "        self.out = nn.Linear(h2, out_features)  # Output layer\n",
        "2. torch.nn.functional (Functional API for Neural Networks)\n",
        "This module provides activation functions and other operations.\n",
        "\n",
        "Used components:\n",
        "\n",
        "F.relu() â†’ ReLU (Rectified Linear Unit) activation function to introduce non-linearity.\n",
        "Example from the code:\n",
        "\n",
        "python\n",
        "Copy\n",
        "Edit\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def forward(self, x):\n",
        "    x = F.relu(self.fc1(x))  # Activation for first hidden layer\n",
        "    x = F.relu(self.fc2(x))  # Activation for second hidden layer\n",
        "    x = self.out(x)  # Output layer\n",
        "    return x\n",
        "3. torch.optim (Optimization Module)\n",
        "This module provides optimizers that help adjust the weights during training.\n",
        "\n",
        "Used components:\n",
        "\n",
        "torch.optim.Adam() â†’ Adam optimizer, which updates the model parameters based on gradients.\n",
        "Example from the code:\n",
        "\n",
        "python\n",
        "Copy\n",
        "Edit\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "4. torch.manual_seed() (Random Seed for Reproducibility)\n",
        "This function ensures the random initialization of weights is the same each time the program runs.\n",
        "\n",
        "Example from the code:\n",
        "\n",
        "python\n",
        "Copy\n",
        "Edit\n",
        "torch.manual_seed(41)\n",
        "5. torch.no_grad() (Disables Gradient Calculation)\n",
        "During testing, we donâ€™t need to calculate gradients, so we disable them to save memory and speed up computations.\n",
        "\n",
        "Example from the code:\n",
        "\n",
        "python\n",
        "Copy\n",
        "Edit\n",
        "with torch.no_grad():\n",
        "    y_eval = model.forward(x_test)  # Get predictions\n",
        "6. Tensor Conversions (torch.FloatTensor and torch.LongTensor)\n",
        "PyTorch models work with tensors, so we must convert data from NumPy arrays.\n",
        "\n",
        "Used components:\n",
        "\n",
        "torch.FloatTensor() â†’ Converts feature data (x_train, x_test) to float tensors.\n",
        "torch.LongTensor() â†’ Converts labels (y_train, y_test) to long tensors for classification.\n",
        "Example from the code:\n",
        "\n",
        "python\n",
        "Copy\n",
        "Edit\n",
        "x_train = torch.FloatTensor(x_train)\n",
        "y_train = torch.LongTensor(y_train)\n",
        "Summary of Key PyTorch Modules Used\n",
        "Module\tPurpose\n",
        "torch.nn.Module\tBase class for neural networks\n",
        "torch.nn.Linear\tFully connected layers\n",
        "torch.nn.CrossEntropyLoss\tLoss function for classification\n",
        "torch.nn.functional.relu\tActivation function\n",
        "torch.optim.Adam\tOptimizer for training\n",
        "torch.manual_seed\tEnsures reproducibility\n",
        "torch.no_grad()\tDisables gradients during evaluation\n",
        "torch.FloatTensor\tConverts data to float tensors\n",
        "torch.LongTensor\tConverts labels to long tensors\n",
        "These modules form the core of the PyTorch deep learning workflow:\n",
        "\n",
        "Define the model (nn.Module, nn.Linear).\n",
        "Use activation functions (F.relu).\n",
        "Set a loss function (nn.CrossEntropyLoss).\n",
        "Choose an optimizer (torch.optim.Adam).\n",
        "Train the model using loss.backward() and optimizer.step().\n",
        "Evaluate the model using torch.no_grad().\n",
        "Let me know if you need a deeper explanation of any of these"
      ],
      "metadata": {
        "id": "_PUOiwTpVPZx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}